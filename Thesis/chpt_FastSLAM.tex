This chapter introduces the background theory necessary for
development in subsequent chapters, in particular Kalman and Particle
filtering and the application of these techniques to the problem of
simultaneous localisation and mapping (SLAM). First, a notation that
will be used throughout this document is introduced in
Section~\ref{sec:Notation}. Section~\ref{sec:Kalman} gives a brief
overview of the Kalman and Extended Kalman filters (Section~\ref{sec:EKF}).
The particle filter is introduced in Section~\ref{sec:PF}. 


\section {Notation}
\label{sec:Notation}

The pose of a robot is represented by $\x{k}{}{a}$. Superscript $a$
indicates a reference frame and $k$ discrete time. A map of region $a$
at time $k$ is denoted $\map{k}{}{a}$. Individual
particles are distinguished by a particle index superscript $m$:
$\x{k}{a}{m}$ and $\map{k}{a}{m}$. The control input at time $k$ is
$\U{k}$ and an observation at time $k$ is $\z{k}$. Further notation
will be introduced as needed, and is summarised in \refTable{tab:notation}.



\SILENT{
This section describes the notation that will be used throughout the
rest of the document. We reserve letter $k$ to represent discrete
time, letter $t$ will represent continuous time. Letters $a$ and $b$
will be used to index map frames. Letter $m$ is used to represent
particle index, the $m$-th particle or belonging to the $m$-th
particle. Index $i$ is reserved for numbering elements of the finite
sets, that do not directly depend on time, for example the map is a
finite set of landmarks, that does not directly depend on time.

The discrete time index will be a subscript, for example \z{k}. The
element index $i$ will also be subscript, if both time and element
index are present, the time index will be followed by a comma followed
by the element index.

Map and particle indices will be superscripts, if both present, the
map index will be first, followed by a comma followed by the particle
index. For example \x{}{a}{m} means the $m$-th particle in the $a$-th
map. Table~\ref{tab:notation} describes variables we will be using in the
thesis and their meaning.
}

\begin{table}[ht]
\begin{tabular}{|l|l|}
\hline
%
\x{k}{a}{m} & pose of the $m$-th particle in the $a$-th map frame 
              at time $k$. \\
\Xall{k}{a}{m} & path of the $m$-th particle in the $a$-th map frame 
                 from time $0$ to time $k$. \\
%
\U{k}    & control input at time $k$.\\
\Uall{k}{a} & subset of all control inputs up to time $k$, that apply to the map frame $a$.\\
%
\z{k}    & observation at time $k$. \\ 
\Zall{k}{a} & subset of all observations up to time $k$, that apply to the map frame $a$. \\ 
%
\Teleport{k}    & teleportation at time $k$.\\
\TeleportAll{k}{a} & subset of all teleportations up to time $k$, that apply to the map frame $a$.\\
%
\map{k}{a}{m} & map of the $m$-th particle in the map frame $a$ at time $k$\\
\mape{a}{m}{i} & $i$-th map element from the $m$-th particle's map in 
                  the map frame $a$.\\
%
\s{k}{a}{m} & $m$-th particle in the SLAM particle filter at time $k$,
              in the map frame $a$.\\
\Sall{k}{}    & set of all particles in the SLAM particle filter at time $k$.\\
%
\tr{i}{a}{b} & transition vector from map frame $a$ to map frame $b$. \\
%
\Trall{a}{b} & a set of transition vectors from map frame $a$ to $b$.\\
%
%
\sample{a}{p(A)}& $a$ is a sample from the distribution $p(A)$.\\
\gpath{a}{b} & path from map $a$ to map $b$.\\
\hline

\end{tabular}
\caption{Notation used throughout the thesis.}
\label{tab:notation}
\end{table}


\section{Kalman Filter}
\label{sec:Kalman}
%A bit of history
R.E. Kalman published his famous paper describing a recursive solution
to the linear filtering problem in 1960 \cite{kalman60}. Since then
the Kalman filter has been the subject of extensive research and
application in various fields of science. It is used heavily in
robotics for localisation and mapping purposes, and is briefly
described below.

The Kalman filter addresses the general problem of estimating the state $
\x{k}{}{} \in \Rset^n$ of a discrete-time controlled process that is
governed by the linear stochastic difference equation
\begin{equation}
\x{k}{}{} = A_k \x{k-1}{}{} + B_k \U{k-1} + w_{k-1},
\label{eqn:kalman_process}
\end{equation}
where $A_k$ is a matrix that describes the evolution of the state from
time $k-1$ to $k$ in the absence of control input or process
noise, matrix $B_k$ relates control input $\U{k-1} \in \Rset^l$, to
the change in the state vector and $w_k$ is process noise.

Indirect measurement of the state $\z{} \in \Rset^m$ is of the form
\begin{equation}
\z{k} = H_k \x{k}{}{} + v_k,
\label{eqn:kalman_obs}
\end{equation}
where $H_k$ is a matrix that relates the state to the observation at
time $k$ and $v_k$ is measurement noise. Both process and
measurement noise are assumed to be zero mean Gaussian with known
covariances $Q_k$ and $R_k$ respectively. Process and measurement
noise are assumed to be independent:

\begin{eqnarray}
w_k \sample{}{} N(0,Q_k),\\
v_k \sample{}{} N(0,R_k).
\end{eqnarray}

An estimate of the system state at time $k$, $\hat{\x{}{}{}}_k$, can be
computed recursively if an estimate of the initial state of the
system is available. The uncertainty of the estimate is assumed to be
Gaussian with covariance $\Sigma_k$.

Kalman filtering consists of two stages: time update and measurement
update. In the time update stage the filter predicts a new state based
on the current state estimate and the process model. The measurement
update stage corrects the estimate using the new measurement. The
state update is given by (see \cite{kalman_intro} for detailed
derivation): 

\begin{eqnarray}
\label{eqn:kalman_x_u}
\hat{\x{}{}{}}_k^\prime &=& A_k \hat{\x{}{}{}}_{k-1} + B_k \U{k-1}\\
\label{eqn:kalman_sigma_u}
\Sigma_k^\prime &=& A_k \Sigma_{k-1} A_k^T + Q_{k-1}
\end{eqnarray}

Equations \refEquation{eqn:kalman_x_u} and
\refEquation{eqn:kalman_sigma_u} constitute the prediction stage of the
Kalman filter. State $\hat{\x{}{}{}}_k^\prime$ estimates system state
at time $k$ before incorporating  measurement and $\Sigma_k^\prime$ is
its covariance.

The measurement update equations are:
\begin{eqnarray}
\label{eqn:kalman_gain}
K_k &=& \Sigma_k^\prime H_k^T (H_k \Sigma_k^\prime H_k^T + R_k )^{-1}\\
\label{eqn:kalman_x_obs}
\hat{\x{}{}{}}_k &=& \hat{\x{}{}{}}_k^\prime + 
                      K_k (\z{k} - H_k \hat{\x{}{}{}}_k^\prime)\\
\label{eqn:kalman_sigma_obs}
\Sigma_k &=& (I - K_k H_k) \Sigma_k^\prime
\end{eqnarray}

Equation \refEquation{eqn:kalman_gain} computes the Kalman gain,
$K_k$. The Kalman gain defines the contribution of the observation to
the new state estimate. $K_k$ is then used in
\refEquation{eqn:kalman_x_obs} and \refEquation{eqn:kalman_sigma_obs} 
to update the estimate of the state and the corresponding uncertainty
in accordance with the noisy observation $\z{k}$ with covariance
$R_k$.

The Kalman filter provably converges to the true state given the
assumptions of linearity and Gaussian noise \cite{kalman60}. These are
fairly restrictive assumptions, since many real-life problems
are non-linear and are subject to non-Gaussian noise.

\subsection{Extended Kalman Filter (EKF)}
\label{sec:EKF}

%Non-linear problems can be solved with the Extended Kalman Filter.
The Kalman filter approach can be applied to non-linear systems by
using first order Taylor series approximation of the process and
measurement models. This approach is generally known as the Extended
Kalman Filter.

Assume that state \x{k}{}{} evolves according to a non-linear stochastic
difference equation, subject to noise $w_{k}$:

\begin{equation}
   \x{k}{}{} = f (\x{k-1}{}{}, \U{k-1}, w_{k-1}).
\label{eqn:ekf_process}
\end{equation}

No direct measurement of the state is available. Instead the state is
observed via a non-linear function $h$, subject to some noise $v_k$

\begin{equation}
   \z{k} = h (\x{k}{}{}, v_k).
\end{equation}

Process and measurement noise are assumed to be independent and drawn from zero mean
Normal distribution.

The update stage of the EKF computes an preliminary estimate of the state
and updates the uncertainty of the estimate as follows:

\begin{eqnarray}
\label{eqn:ekf_x_u}
\hat{\x{}{}{}}_k^\prime &=& f(\hat{\x{}{}{}}_{k-1},\U{k-1},0)\\
\label{eqn:ekf_sigma_u}
\Sigma_k^\prime &=& A_k \Sigma_{k-1} A_k^T + W_k Q_{k} W_k^T
\end{eqnarray}

Matrices $A_k$ and $W_k$ in the equations above are partial
derivatives of the state evolution function evaluated at
$\hat{\x{}{}{}}_{k-1}$ :

\begin{eqnarray}
A_{k[i,j]} &=& \frac{\partial f_{[i]}}{\partial \x{[j]}{}{}}
              (\hat{\x{}{}{}}_{k-1}, \U{k-1}, 0) \\
W_{k[i,j]} &=& \frac{\partial f_{[i]}}{\partial w_{[j]}}
              (\hat{\x{}{}{}}_{k-1}, \U{k-1}, 0).
\end{eqnarray}


The measurement update stage requires a projection of the state
uncertainty into the observation space. Since the observation function $h$
is non-linear, the uncertainty of the projection is not Gaussian. The
EKF approximates it by a Gaussian as follows:

\begin{eqnarray}
\label{eqn:ekf_gain}
K_k &=& \Sigma_k^\prime H_k^T(H_k\Sigma_k^\prime H_k^T + V_k R_k
V_k^T)^{-1}\\
\label{eqn:ekf_x_obs}
\hat{\x{}{}{}}_k &=& \hat{\x{}{}{}}_k^\prime + 
                      K_k (\z{k} - h(\hat{\x{}{}{}}_k^\prime,0))\\
\label{eqn:ekf_sigma_obs}
\Sigma_k &=& (I - K_k H_k) \Sigma_k^\prime
\end{eqnarray}

Here matrices $H_k$ and $V_k$ are partial derivatives of the
observation function:

\begin{eqnarray}
H_{k[i,j]} &=& \frac{\partial h_{[i]}}{\partial \x{[j]}{}{}}
              (\hat{\x{}{}{}}_{k-1}^\prime, 0)\\
V_{k[i,j]} &=& \frac{\partial h_{[i]}}{\partial v_{[j]}}
              (\hat{\x{}{}{}}_{k-1}^\prime, 0).
\end{eqnarray}



\SILENT{
EKF operation is similar to that of the Kalman filter: first compute
the Kalman gain
\refEquation{eqn:ekf_gain}, and then update the mean
\refEquation{eqn:ekf_x_obs} and the covariance
\refEquation{eqn:ekf_sigma_obs} of the state variable. The only
difference is that instead of true noise covariances, first order
Taylor series approximation is used. 
}

Unlike the Kalman filter, the EKF is not guaranteed to converge, and
is likely to fail if the system is highly non-linear. However there
are many successful applications of the EKF in various fields of
research. In robotics the EKF has been successfully used for
localisation \cite{Jensfelt99} and SLAM \cite{dissanayake01,
  bosse03atlas,guivant00:_auton_navig_map_using_laser} problems.


\section{Particle Filter}
\label{sec:PF}

Particle filters have proven to be a useful tool in robotics, used for
localisation \cite{Thrun00j,thrun00}, mapping
\cite{fastslam} and people tracking
\cite{sidenbladh00stochastic}, to name just a few applications. 
In this thesis a particle filter is used for mapping and localisation.

The particle filter addresses a similar problem to that of the Kalman
filter - to track a variable of interest as it evolves over
time. Unlike the Kalman filter, a particle filter approximates the
posterior distribution of the state by a set of weighted
particles. Given enough particles, one can approximate any
distribution, hence particle filters can be applied to non-linear
problems and will generally provide a better approximation than an
EKF.

%%% For linear systems with Gaussian noise and a reasonably accurate
%%% initial estimate, the Kalman filter is more appropriate.
 
%%% As previously mentioned the problem is similar to that addressed by
%%% the Kalman filter, but is more general. Unlike the Kalman filter, a
%%% particle filter is not restricted by the Gaussian noise
%%% assumptions. 

In the present context of mapping and localisation, the task of a
particle filter is to track the state of a controllable and partially
observable discrete time Markov chain\cite{gilks1996mcm}. The state of the
Markov chain at time $k$ is denoted by \x{k}{}{}. The state depends on
the previous state
\x{k-1}{}{} and the control $\U{k-1}$ asserted in the time interval
$(k-1;k]$, according to the probabilistic law

\begin{equation}
p( \x{k}{}{} | \x{k-1}{}{}, \U{k-1}).
\label{eqn:pf_px}
\end{equation}

Note that the Kalman filter and EKF state evolution equations
\refEquation{eqn:kalman_process},\refEquation{eqn:ekf_process}, can be
expressed in the form of a probability like the one above. The state
of the Markov chain is not directly observable, instead a stochastic
projection \z{k} of the true state \x{k}{}{} generated via the
probabilistic law is available

\begin{equation}
p (\z{k} | \x{k}{}{}).
\label{eqn:pf_pz}
\end{equation}

The initial state \x{0}{}{} is given by some distribution
$p(\x{0}{}{})$. The particle filter algorithm is presented in
pseudo-code in the \refFigure{fig:pf_algorithm} and briefly summarised
below.

\begin{figure}[h]
{ \tt %\small 
\hspace*{.1cm} {\it //Initialise} \\
\hspace*{.1cm} {\bf for} $m$ = 1 to $M$ \\
\hspace*{.5cm}  $\x{0}{}{m} \sample{}{} p(\x{0}{}{})$\\
\hspace*{.5cm}  add \x{0}{}{m} to ${\bf X}_0$\\
\hspace*{.1cm} {\bf endfor}\\
\hspace*{.1cm} k = 0; \\
\hspace*{.1cm} {\it //Main Loop} \\
\hspace*{.1cm} {\bf while} MoreDataIsAvailable \\
\hspace*{.5cm}   {\it //Propagate particles} \\
\hspace*{.5cm}   {\bf for} $m$ = 1 to $M$ \\
\hspace*{.9cm}      get \x{k-1}{}{m} from ${\bf X}_{k-1}$\\
\hspace*{.9cm}      $\x{k}{}{m} \sample{}{} p(\x{k}{}{} 
                      |\x{k-1}{}{m}, \U{k-1})$\\
\hspace*{.9cm}      add \x{k}{}{m} to ${\bf X}_k^\prime$\\
\hspace*{.5cm}   {\bf endfor}\\
\hspace*{.5cm}   {\it //Update particle weights}\\
\hspace*{.5cm}   {\bf for} $m$ = 1 to $M$ \\
\hspace*{.9cm}      $\w{k}{}{m} = p(\z{k} | \x{k}{}{m})$\\
\hspace*{.9cm}      add \w{k}{}{m} to ${\bf W}$\\
\hspace*{.5cm}   {\bf endfor}\\
\hspace*{.5cm}   {\it //Resample according to the weight.}\\
\hspace*{.5cm}  ${\bf X}_k$ = resample$({\bf X}_k^\prime, {\bf W})$\\
\hspace*{.5cm}  k = k + 1\\
\hspace*{.1cm} {\bf end}
}
\caption{Particle filter algorithm.}
\label{fig:pf_algorithm}
\end{figure}

First the set of all particles ${\bf X}_0$ is initialised by drawing
$M$ samples from the initial distribution $p(\x{0}{}{})$. For
simplicity we assume, without loss of generality, that control
inputs and observations arrive at the same time. The particle filter
first predicts the state by sampling from the distribution
$p(\x{k}{}{} | \x{k-1}{}{m}, \U{k-1})$. This sampling is applied to
every particle in the set ${\bf X}_{k-1}$ and a new set ${\bf
X}_k^\prime$ is created. Particles in the new set are then assigned a
weight, which is equal to the likelihood of the state represented by
the particle, given the observation \z{k}. Finally, the set of all
particles ${\bf X}_k$ is computed by sampling with replacement from
the set ${\bf X}_k^\prime$ in proportion to the weight of the
particles.

The resampling step selects particles that have higher likelihood
associated with them with higher probability, and in doing so a new
set ${\bf X}_k$ is created that approximates a random sample from
$p(\x{k}{}{}|\Zall{k}{})$, where \Zall{k}{} is a set of all
observations up to time $k$. The resampling step is not required after
every observation. 

%%% In fact it is best not to resample very frequently,
%%% as this can lead to overconfident distribution. The best resampling
%%% strategy varies from one problem to another.
 
\SILENT{Would be good to give some reference to smart
resampling strategies, entropy based maybe?}



% LocalWords:  Kalman odometry EKF FastSLAM Bayes MCL Lu Milios Konolige Gutman
% LocalWords:  Thrun Bosse Ferguson resampling Gaussians linearisation
